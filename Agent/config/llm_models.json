{
  "providers": {
    "openai": {
      "name": "OpenAI",
      "default_model": "gpt-4o-mini"
    },
    "anthropic": {
      "name": "Anthropic (Claude)",
      "default_model": "claude-sonnet-4-5-20250929"
    },
    "gemini": {
      "name": "Google Gemini",
      "default_model": "gemini-2.5-flash"
    },
    "deepseek": {
      "name": "DeepSeek",
      "default_model": "deepseek-chat"
    },
    "ollama": {
      "name": "Ollama (Local)",
      "default_model": "llama3.2"
    }
  },
  "models": {
    "gpt-3.5-turbo": {
      "provider": "openai",
      "display_name": "GPT-3.5 Turbo",
      "pricing": {
        "input": 0.0005,
        "output": 0.0015
      },
      "max_context_tokens": 4096
    },
    "gpt-4o": {
      "provider": "openai",
      "display_name": "GPT-4o",
      "pricing": {
        "input": 0.005,
        "output": 0.015
      },
      "max_context_tokens": 131072
    },
    "gpt-4-turbo": {
      "provider": "openai",
      "display_name": "GPT-4 Turbo",
      "pricing": {
        "input": 0.01,
        "output": 0.03
      },
      "max_context_tokens": 131072
    },
    "gpt-4o-mini": {
      "provider": "openai",
      "display_name": "GPT-4o Mini",
      "pricing": {
        "input": 0.00015,
        "output": 0.0006
      },
      "max_context_tokens": 131072
    },
    "claude-sonnet-4-5-20250929": {
      "provider": "anthropic",
      "display_name": "Claude Sonnet 4.5",
      "pricing": {
        "input": 0.003,
        "output": 0.015
      },
      "max_context_tokens": 200000,
      "notes": "Latest Claude model, best for complex agents & coding"
    },
    "claude-opus-4-1-20250805": {
      "provider": "anthropic",
      "display_name": "Claude Opus 4.1",
      "pricing": {
        "input": 0.015,
        "output": 0.075
      },
      "max_context_tokens": 200000,
      "notes": "Exceptional for specialized complex tasks"
    },
    "claude-sonnet-4-20250514": {
      "provider": "anthropic",
      "display_name": "Claude Sonnet 4",
      "pricing": {
        "input": 0.003,
        "output": 0.015
      },
      "max_context_tokens": 200000
    },
    "claude-3-7-sonnet-20250219": {
      "provider": "anthropic",
      "display_name": "Claude 3.7 Sonnet",
      "pricing": {
        "input": 0.003,
        "output": 0.015
      },
      "max_context_tokens": 200000
    },
    "claude-3-5-haiku-20241022": {
      "provider": "anthropic",
      "display_name": "Claude 3.5 Haiku",
      "pricing": {
        "input": 0.0008,
        "output": 0.004
      },
      "max_context_tokens": 200000,
      "notes": "Fastest Claude model"
    },
    "claude-3-haiku-20240307": {
      "provider": "anthropic",
      "display_name": "Claude 3 Haiku",
      "pricing": {
        "input": 0.00025,
        "output": 0.00125
      },
      "max_context_tokens": 200000
    },
    "gemini-2.5-pro": {
      "provider": "gemini",
      "display_name": "Gemini 2.5 Pro",
      "pricing": {
        "input": 0.00125,
        "output": 0.01
      },
      "max_context_tokens": 2097152,
      "notes": "State-of-the-art multipurpose model, excels at coding and complex reasoning"
    },
    "gemini-2.5-flash": {
      "provider": "gemini",
      "display_name": "Gemini 2.5 Flash",
      "pricing": {
        "input": 0.0003,
        "output": 0.0025
      },
      "max_context_tokens": 1048576,
      "notes": "First hybrid reasoning model with thinking budgets"
    },
    "gemini-2.5-flash-preview-09-2025": {
      "provider": "gemini",
      "display_name": "Gemini 2.5 Flash Preview",
      "pricing": {
        "input": 0.0003,
        "output": 0.0025
      },
      "max_context_tokens": 1048576,
      "is_preview": true,
      "notes": "Preview model, may change before becoming stable"
    },
    "gemini-2.0-flash-exp": {
      "provider": "gemini",
      "display_name": "Gemini 2.0 Flash (Experimental)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 1048576,
      "is_experimental": true,
      "notes": "Experimental model, free to use but may change"
    },
    "gemini-flash-lite-8b-001": {
      "provider": "gemini",
      "display_name": "Gemini Flash-Lite 8B",
      "pricing": {
        "input": 0.0001,
        "output": 0.0004
      },
      "max_context_tokens": 1048576,
      "notes": "Lightweight model for high-volume, low-latency tasks"
    },
    "gemini-1.5-pro": {
      "provider": "gemini",
      "display_name": "Gemini 1.5 Pro",
      "pricing": {
        "input": 0.00125,
        "output": 0.005
      },
      "max_context_tokens": 2097152
    },
    "gemini-1.5-flash": {
      "provider": "gemini",
      "display_name": "Gemini 1.5 Flash",
      "pricing": {
        "input": 0.000075,
        "output": 0.0003
      },
      "max_context_tokens": 1048576
    },
    "gemini-1.5-flash-8b": {
      "provider": "gemini",
      "display_name": "Gemini 1.5 Flash-8B",
      "pricing": {
        "input": 0.00004,
        "output": 0.00015
      },
      "max_context_tokens": 1048576
    },
    "gemini-1.0-pro": {
      "provider": "gemini",
      "display_name": "Gemini 1.0 Pro",
      "pricing": {
        "input": 0.0005,
        "output": 0.0015
      },
      "max_context_tokens": 32768,
      "notes": "Legacy model"
    },
    "deepseek-chat": {
      "provider": "deepseek",
      "display_name": "DeepSeek Chat",
      "pricing": {
        "input": 0.00014,
        "output": 0.00028
      },
      "max_context_tokens": 65536,
      "notes": "Default DeepSeek model via Anthropic API compatibility"
    },
    "deepseek-r1": {
      "provider": "deepseek",
      "display_name": "DeepSeek R1",
      "pricing": {
        "input": 0.0002,
        "output": 0.0008
      },
      "max_context_tokens": 65536
    },
    "deepseek-v3": {
      "provider": "deepseek",
      "display_name": "DeepSeek V3",
      "pricing": {
        "input": 0.00025,
        "output": 0.001
      },
      "max_context_tokens": 65536
    },
    "llama3.2": {
      "provider": "ollama",
      "display_name": "Llama 3.2 (3B)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 131072,
      "notes": "Local model, free to use. Fast and efficient."
    },
    "llama3.2:1b": {
      "provider": "ollama",
      "display_name": "Llama 3.2 (1B)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 131072,
      "notes": "Local model, very lightweight and fast"
    },
    "llama3.1": {
      "provider": "ollama",
      "display_name": "Llama 3.1 (8B)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 131072,
      "notes": "Local model, better reasoning capabilities"
    },
    "llama3.3:70b": {
      "provider": "ollama",
      "display_name": "Llama 3.3 (70B)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 131072,
      "notes": "Local model, most powerful. Requires ~40GB RAM"
    },
    "mistral": {
      "provider": "ollama",
      "display_name": "Mistral (7B)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 32768,
      "notes": "Local model, balanced performance"
    },
    "codellama": {
      "provider": "ollama",
      "display_name": "Code Llama (7B)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 16384,
      "notes": "Local model, optimized for code generation"
    },
    "phi3": {
      "provider": "ollama",
      "display_name": "Phi-3 (3.8B)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 131072,
      "notes": "Local model, Microsoft's efficient model"
    },
    "gemma2": {
      "provider": "ollama",
      "display_name": "Gemma 2 (9B)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 8192,
      "notes": "Local model, Google's open model"
    },
    "deepseek-coder": {
      "provider": "ollama",
      "display_name": "DeepSeek Coder (6.7B)",
      "pricing": {
        "input": 0.0,
        "output": 0.0
      },
      "max_context_tokens": 16384,
      "notes": "Local model, specialized for coding tasks"
    }
  },
  "metadata": {
    "last_updated": "2025-10-04",
    "pricing_unit": "per_1M_tokens_usd",
    "references": {
      "gemini": "https://ai.google.dev/gemini-api/docs/pricing",
      "anthropic": "https://docs.claude.com/en/docs/about-claude/models/overview",
      "openai": "https://openai.com/api/pricing/"
    }
  }
}
